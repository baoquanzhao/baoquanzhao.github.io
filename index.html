<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Baoquan Zhao's Homepage</title>

    <meta name="description" content="Source code generated using layoutit.com">
    <meta name="author" content="LayoutIt!">

    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.4.0/css/font-awesome.css">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Tenor+Sans">
    <link href="css/style.css" rel="stylesheet">

  </head>
  <body>
  	<!-- <p>Baoquan Zhao's Homepage</p> -->
    <div class="container"  id="container_header">
    	<div class="row" id="header">
    		<div class="col-md-6" id="header_left"><a href="index.html">Baoquan Zhao's Homepage</a></div>
    		<div class="col-md-6" id="header_right">
    			<ul class="nav">
						<li class="nav-item">
							<a class="nav-link active" href="#bio_div" id="home_a">Home</a>
						</li>
					
						<li class="nav-item">
							<a class="nav-link" href="#exp_div">Research</a>
						</li>
						<li class="nav-item">
							<a class="nav-link" href="#pub_div">Publications</a>
						</li>
						<li class="nav-item">
							<a class="nav-link" href="#ser_div">Services</a>
						</li>
						<!-- <li class="nav-item">
							<a class="nav-link" href="#res_div">Teaching</a>
						</li> -->
					</ul>
    		</div>
    	</div>
    </div>

    <div class="container" id="bio_div" >
    	<div class="row">
    		<div class="blk">
    			<h2>About Me</h2>
	    				<div id="wrap_img">
								<img alt="" src="img/zbq.jpg" id="bio_img">
							</div>
							<div id="wrap_txt">
									<p>
									<strong>Baoquan Zhao (赵宝全)</strong> is currently an associate professor at the <a target="_blank" href="https://sai.sysu.edu.cn/"> School of Artificial Intelligent</a>, <a target="_blank" href="https://www.sysu.edu.cn/">Sun Yat-sen University</a>, China. Prior to his current position, he was a Research Fellow under the supervison of <a href="https://personal.ntu.edu.sg/wslin/">Prof. Weisi Lin</a> at the <a target="_blank" href="http://scse.ntu.edu.sg/">School of Computer Science and Engineering (SCSE)</a>, <a target="_blank" href="https://www.ntu.edu.sg/">Nanyang Technological University, Singapore</a>, from Sep. 2018 to Jan. 2022. He received his Ph.D. degree in computer science from <a target="_blank" href="http://www.sysu.edu.cn/">Sun Yat-sen University</a>, Guangzhou, China, in 2017. From Dec. 2014 to Dec. 2015, he spent one year visiting the <a target="_blank" href="https://informatics.njit.edu/">Department of Informatics</a>, <a target="_blank" href="https://www.njit.edu/">New Jersey Institute of Technology</a>, USA.<br>
									He has been serving as a reviewer of IEEE Transactions on Image Processing, IEEE Transactions on Multimedia, Information Science, Pattern Recognition, Neurocomputing, Signal Processing etc, and was a technical program committee member of IEEE ICME, IEEE ICIP and AMIA. 
									His research interests are in the areas of point cloud processing and compression, visual information analysis, multimedia systems and applications (especially open educational resources), etc.
									</p>
									<p>
									<i class="fa fa-envelope-o" aria-hidden="true"></i> &nbsp;&nbsp;<a href="">zhaobaoquan@mail.sysu.edu.cn</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<i class="fa fa-map-marker" aria-hidden="true"></i> &nbsp;&nbsp;Tangjiawan, Zhuhai, Guangdong, 519082, China</p>
							</div>
	    		</div>
    	</div>
		</div>



		<div class="container" id="exp_div">
			<div class="row">
    		<div class="blk">
    			<h2>Research Experience</h2>
    				
    				<div class="row">
							<div class="col-md-8">
								<p class="sub_title">Theme I: 3D Point Cloud Processing and Compression</p>
								<p>The wide availability of 3D scanning equipment and ever-growing 3D applications are generating more and more point cloud data at an unprecedented rate, and this poses great challenges for efficient and economic data storage, management, transmission and processing. Recent work under this theme:</p> 
								<ul>
									<li>Image-based point cloud attribute compression</li>
									<li>Point cloud simplification and mesh reconstruction</li>
									<li>Deep learning based point cloud processing</li>
									<li>Point cloud parameterization</li>
								</ul>
							</div>
							<div class="col-md-4"><img alt="" src="img/theme1.gif" class="div_img">
							</div>
						</div>

						
    				<div class="row">
							<div class="col-md-8">
								<p class="sub_title">Theme II: Open Educational Resource (OER) Retrieval, Analysis and Systems</p>
								<p>With recent developments and advances in distance learning and MOOCs, the amount of open educational videos on the Internet has grown dramatically in the past decade. However, most of these videos are lengthy and lack of high-quality indexing and annotations, which triggers an urgent demand for efficient and effective tools that facilitate video content navigation and exploration. Work under this theme:</p> 
								<ul>
									<li>Multi-modal information (including image, speech, text, human action etc.) extraction and fusion</li>
									<li>Visual-texual educational video summarization</li>
									<li>Slide-based lecture video content structuring based on multi-modal cues</li>
									<li>Visual systems for OER video retrival and content exploration</li>
								</ul>
							</div>
							<div class="col-md-4"><img alt="" src="img/theme2.gif" class="div_img">
							</div>
						</div>
    		</div>
    	</div>
    </div>

    <div class="container" id="pub_div">
			<div class="row">
    		<div class="blk">
    			<h2>Selected Publications</h2>
    			<p class="sub_title">Point Cloud Processing and Compression</p>


    			    <div class="row pub_div_blk">
    					<div class="col-md-3 img_div">
								<img alt="" src="img/placeholder.png" class="div_img">
							</div>
							<div class="col-md-9">
								<p class="paper_info">C. Lv, W. Lin, and <span class="author">B. Zhao</span>, <span class="paper_title">Approximate Intrinsic Voxel Structure for Point Cloud Simplification</span>, <span class="journal">IEEE Transactions on Image Processing</span>, vol. 30, pp. 7241-7255, 2021</p>
								<p class="paper_abs"></p>
								<p>
									<span class="bib">[<a href="#" target="_blank"  class="btn-xs btn-link" data-toggle="collapse" data-target="#tip2021">Bibtex</a>]</span>
								<div id="tip2021" class="collapse">
									@article{lv2021approximate,<br>
									  title={Approximate intrinsic voxel structure for point cloud simplification},<br>
									  author={Lv, Chenlei and Lin, Weisi and Zhao, Baoquan},<br>
									  journal={IEEE Transactions on Image Processing},<br>
									  volume={30},<br>
									  pages={7241--7255},<br>
									  year={2021},<br>
									  publisher={IEEE}
									}
								</div>
								</p> 
							</div>
						</div>

    			<div class="row pub_div_blk">
    					<div class="col-md-3 img_div">
								<img alt="" src="img/placeholder.png" class="div_img">
							</div>
							<div class="col-md-9">
								<p class="paper_info"><span class="author">B. Zhao</span>, W. Lin, and C. Lv, <span class="paper_title">Fine-Grained Patch Segmentation and Rasterization for 3D Point Cloud Attribute Compression</span>, <span class="journal">IEEE Transactions on Circuits and Systems for Video Technology</span>, vol. 31, no. 12, pp. 4590-4602, 2021</p>
								<p class="paper_abs">A complexity-aware heat kernel signature (HKS)-based patch segmentation method is developed to effectively partition a given point into fine-grained patches that are suitable for attribute image generation while well preserving the inherent spatial correlation among points.<br>
								A new patch rasterization and rectification method is developed to achieve a balance between assignment energy and intrinsic patch shape preserving.</p>
								<p>
									<span class="bib">[<a href="#" target="_blank"  class="btn-xs btn-link" data-toggle="collapse" data-target="#tcsvt2021">Bibtex</a>]</span>
								<div id="tcsvt2021" class="collapse">
									@article{zhao2021fine,<br>
									  title={Fine-grained patch segmentation and rasterization for 3-d point cloud attribute compression},<br>
									  author={Zhao, Baoquan and Lin, Weisi and Lv, Chenlei},<br>
									  journal={IEEE Transactions on Circuits and Systems for Video Technology},<br>
									  volume={31},<br>
									  number={12},<br>
									  pages={4590--4602},<br>
									  year={2021},<br>
									  publisher={IEEE}<br>
									}
										}
								</div>
								</p> 
							</div>
						</div>

    			<div class="row pub_div_blk">
    					<div class="col-md-3">
								<img alt="" src="img/tmm2021.jpg" class="div_img">
							</div>
							<div class="col-md-9">
								<p class="paper_info">C. Lv, W. Lin, and <span class="author">B. Zhao</span>, <span class="paper_title">Voxel Structure-based Mesh Reconstruction from a 3D Point Cloud</span>, <span class="journal">IEEE Transactions on Multimedia</span>, vol. 24, pp. 1815-1829, 2021</p>
								<p class="paper_abs">A novel voxel structure-based framework was introduced to reconstruct an isotropic mesh from a point cloud keeping important geometric features such as external and internal edges.</p>
								<p>
									<span class="proj_page">[<a href="https://aliexken.github.io/subSet/MeshReconstruction.html" target="_blank">Project page</a>]</span>
									<span class="data">[<a href="https://drive.google.com/drive/folders/1SPpBB7GhjEHakJtE0yMeyBq2JjLb1GWE" target="_blank">Data</a>]</span>
									<span class="demo">[<a href="https://www.youtube.com/watch?v=8k49clewD0c&ab_channel=LVChenlei" target="_blank">Demo</a>]</span>
									<span class="bib">[<a href="#" target="_blank"  class="btn-xs btn-link" data-toggle="collapse" data-target="#Bibtex_tmm2021">Bibtex</a>]</span>
									
								  <div id="Bibtex_tmm2021" class="collapse">


										@article{lv2021voxel,<br>
										  title={Voxel structure-based mesh reconstruction from a 3D point cloud},<br>
										  author={Lv, Chenlei and Lin, Weisi and Zhao, Baoquan},<br>
										  journal={IEEE Transactions on Multimedia},<br>
										  volume={24},<br>
										  pages={1815--1829},<br>
										  year={2021},<br>
										  publisher={IEEE}<br>
										}
								  </div>
								</p> 
							</div>
					</div>


					<div class="row pub_div_blk">
    					<div class="col-md-3">
								<img alt="" src="img/icip2019.jpg" class="div_img">
							</div>
							<div class="col-md-9">
								<p class="paper_info">J. U. Hou, <span class="author">B. Zhao</span>, N. Ansari, and W. Lin, <span class="paper_title">Range Image Based Point Cloud Colorization Using Conditional Generative Model</span>, <span class="journal">IEEE International Conference on Image Processing (ICIP)</span>, pp. 524-528, 2019</p>
								<p class="paper_abs">We introduce an automatic colorization scheme based on a deep generative network for 3D point clouds. The proposed approach uses the range images of point could geometry and trains a conditional generative adversarial network to predict the color of those images.</p>
								<p>
									<span class="bib">[<a href="#" target="_blank"  class="btn-xs btn-link" data-toggle="collapse" data-target="#icip2019">Bibtex</a>]</span>
								<div id="icip2019" class="collapse">
											@inproceedings{hou2019range,<br>
											  title={Range Image Based Point Cloud Colorization Using Conditional Generative Model},<br>
											  author={Hou, Jong-Uk and Zhao, Baoquan and Ansari, Naushad and Lin, Weisi},<br>
											  booktitle={2019 IEEE International Conference on Image Processing (ICIP)},<br>
											  pages={524--528},<br>
											  year={2019},<br>
											  organization={IEEE}<br>
											}
								</div>
								</p> 
							</div>
						</div>





					<p class="sub_title">Open Educational Resources Retrieval, Analysis and Systems</p>
					<div class="row pub_div_blk">
    					<div class="col-md-3">
								<img alt="" src="img/icme2019_1.gif" class="div_img">
							</div>
							<div class="col-md-9">
								<p class="paper_info"><span class="author">B. Zhao</span>, S. Xu, S. Lin, R. Wang, and X. Luo, <span class="paper_title">A New Visual Interface for Searching and Navigating Slide-Based Lecture Videos</span>, <span class="journal">2019 IEEE International Conference on Multimedia and Expo (ICME)</span>, pp. 928-933, 2019</p>
								<p class="paper_abs">The interface comprehensively derives versatile semantic clues for video content indexing and visual aid generation according to visual elements, text, and mathematical expressions included on lecture slides, speeches recorded, as well as mouse and cursor pointing actions captured during a lecture.</p>
								<p>
									<span class="demo">[<a href="img/Demo-ICME.mp4" download>Demo (MP4, ~60MB)</a>]</span>
									<span class="bib">[<a href="#" target="_blank"  class="btn-xs btn-link" data-toggle="collapse" data-target="#icme2019_1">Bibtex</a>]</span>
								<div id="icme2019_1" class="collapse">
										@inproceedings{zhao2019new,<br>
										  title={A new visual interface for searching and navigating slide-based lecture videos},<br>
										  author={Zhao, Baoquan and Xu, Songhua and Lin, Shujin and Wang, Ruomei and Luo, Xiaonan},<br>
										  booktitle={2019 IEEE International Conference on Multimedia and Expo (ICME)},<br>
										  pages={928--933},<br>
										  year={2019},<br>
										  organization={IEEE}<br>
										}
								</div>
								</p> 
							</div>
						</div>

						<div class="row pub_div_blk">
    					<div class="col-md-3">
								<img alt="" src="img/icme2019_2.jpg" class="div_img">
							</div>
							<div class="col-md-9">
								<p class="paper_info">C. Xu, R. Wang, S. Lin, X. Luo, <span class="author">B. Zhao</span>, L. Shao, and M. Hu, <span class="paper_title">Lecture2Note: Automatic Generation of Lecture Notes from Slide-Based Educational Videos</span>, <span class="journal">2019 IEEE International Conference on Multimedia and Expo (ICME)</span>, pp. 898-903, 2019</p>
								<p class="paper_abs">Most educational/lecture videos on the internet are lengthy and lack of elaborate annotations. we introduced an novel method to generate note-like video summarizations by establishing the semantic relationship between visual entities in the slide-based lecture video and their descriptive speech texts.</p>
								<p>
									<span class="bib">[<a href="#" target="_blank"  class="btn-xs btn-link" data-toggle="collapse" data-target="#icme2019_2">Bibtex</a>]</span>
								<div id="icme2019_2" class="collapse">
										@inproceedings{xu2019lecture2note,<br>
										  title={Lecture2Note: Automatic Generation of Lecture Notes from Slide-Based Educational Videos},<br>
										  author={Xu, Chengpei and Wang, Ruomei and Lin, Shujin and Luo, Xiaonan and Zhao, Baoquan and Shao, Lijie and Hu, Mengqiu},<br>
										  booktitle={2019 IEEE International Conference on Multimedia and Expo (ICME)},<br>
										  pages={898--903},<br>
										  year={2019},<br>
										  organization={IEEE}<br>
										}
								</div>
								</p> 
							</div>
						</div>

						<div class="row pub_div_blk">
    					<div class="col-md-3 img_div">
								<img alt="" src="img/nca2017.jpg" class="div_img">
							</div>
							<div class="col-md-9">
								<p class="paper_info"><span class="author">B. Zhao</span>, S. Lin, X. Qi, R. Wang, and X. Luo, <span class="paper_title">A Novel Approach to Automatic Detection of Presentation Slides in Educational Videos</span>, <span class="journal">Neural Computing and Applications</span>,  vol. 29, no. 5, pp. 1369-1382, 2018</p>
								<p class="paper_abs">The proposed approach mainly involves five core components: shot boundary detection, training instances collection, shot classification, slide region detection and slide transition detection. </p>
								<p>
								
									<span class="bib">[<a href="#" target="_blank"  class="btn-xs btn-link" data-toggle="collapse" data-target="#nca2018">Bibtex</a>]</span>
								<div id="nca2018" class="collapse">
									@article{zhao2018novel,<br>
									  title={A novel approach to automatic detection of presentation slides in educational videos},<br>
									  author={Zhao, Baoquan and Lin, Shujin and Qi, Xin and Wang, Ruomei and Luo, Xiaonan},<br>
									  journal={Neural Computing and Applications},<br>
									  volume={29},<br>
									  number={5},<br>
									  pages={1369--1382},<br>
									  year={2018},<br>
									  publisher={Springer}<br>
									}
								</div>
								</p> 
							</div>
						</div>

						<div class="row pub_div_blk">
    					<div class="col-md-3 img_div">
								<img alt="" src="img/mm2017.gif" class="div_img">
							</div>
							<div class="col-md-9">
								<p class="paper_info"><span class="author">B. Zhao</span>, S. Lin, X. Luo, S. Xu, and R. Wang, <span class="paper_title">A Novel System for Visual Navigation of Educational Videos Using Multimodal Cues</span>, <span class="journal">ACM Multimedia</span>, pp. 1680-1688, 2017</p>
								<p class="paper_abs">The system tightly integrates multimodal cues obtained from the visual, audio and textual channels of educational videos and presents them with a series of interactive visualization components. With the help of this system, users can explore the educational video content using multiple levels of details to identify content of interest with ease.</p>
								<p>
										<span class="demo">[<a href="img/Demo-ACMMM.avi" download>Demo (AVI, ~60MB)</a>]</span>
									<span class="bib">[<a href="https://www.researchgate.net/publication/320541540" target="_blank"  class="btn-xs btn-link" data-toggle="collapse" data-target="#mm2017">Bibtex</a>]</span>
								<div id="mm2017" class="collapse">
									@inproceedings{zhao2017novel,<br>
									  title={A novel system for visual navigation of educational videos using multimodal cues},<br>
									  author={Zhao, Baoquan and Lin, Shujin and Luo, Xiaonan and Xu, Songhua and Wang, Ruomei},<br>
									  booktitle={Proceedings of the 25th ACM international conference on Multimedia},<br>
									  pages={1680--1688},<br>
									  year={2017}<br>
									}
								</div>
								</p> 
							</div>
						</div>

						<div class="row pub_div_blk">
    					<div class="col-md-3 img_div">
								<img alt="" src="img/sa2017.jpg" class="div_img">
							</div>
							<div class="col-md-9">
								<p class="paper_info"><span class="author">B. Zhao</span>, S. Lin, X. Qi, Z. Zhang, X. Luo, and R. Wang, <span class="paper_title">Automatic Generation of Visual-Textual Web Video Thumbnail</span>, <span class="journal">ACM SIGGRAPH ASIA (Posters)</span>,  pp. 1-2, 2017</p>
								<p class="paper_abs">We proposed an automatic approach to generate magazine-cover-like thumbnail using the salient visual and textual metadata extracted from video. Compared with traditional snapshot, the synthesized thumbnail is more informative and attractive, which would be helpful for online video selection.</p>
								<p>
									<span class="bib">[<a href="#" target="_blank"  class="btn-xs btn-link" data-toggle="collapse" data-target="#sa2017">Bibtex</a>]</span>
								<div id="sa2017" class="collapse">
									@incollection{zhao2017automatic,<br>
									  title={Automatic generation of visual-textual web video thumbnail},<br>
									  author={Zhao, Baoquan and Lin, Shujin and Qi, Xin and Zhang, Zhiquan and Luo, Xiaonan and Wang, Ruomei},<br>
									  booktitle={SIGGRAPH Asia 2017 Posters},<br>
									  pages={1--2},<br>
									  year={2017}<br>
									}
								</div>
								</p> 
							</div>
						</div>

						<div class="row pub_div_blk">
    					<div class="col-md-3 img_div">
    						<img alt="" src="img/jamia2016_1.jpg" class="div_img" style="top:25%;">
								<img alt="" src="img/jamia2016.gif" class="div_img" style="top:30%;">
							</div>
							<div class="col-md-9">
								<p class="paper_info"><span class="author">B. Zhao</span>, S. Xu, S. Lin, X. Luo, and L. Duan,<span class="paper_title">A New Visual Navigation System for Exploring Biomedical Open Educational Resource (OER) Videos</span>, <span class="journal">Journal of the American Medical Informatics Association</span>,  vol. 23, no. e1, pp. e34-e41, 2016</p>
								<p class="paper_abs">Biomedical videos as open educational resources (OERs) are increasingly proliferating on the Internet. Unfortunately, seeking personally valuable content from among the vast corpus of quality yet diverse OER videos is nontrivial due to limitations of today's keyword- and content-based video retrieval techniques. To address this need, this study introduces a novel visual navigation system that facilitates users' information seeking from biomedical OER videos in mass quantity by interactively offering visual and textual navigational clues that are both semantically revealing and user-friendly.</p>
								<p>
									<span class="demo">[<a href="img/System Architecture Demo.mp4" download>Demo 1: Architecture (MP4, ~18MB)</a>]</span> 
									<span class="demo">[<a href="img/Demo-JAMIA.mp4.mp4" download>Demo 2: System (MP4, ~75MB)</a>]</span>
									<span class="bib">[<a href="#" target="_blank"  class="btn-xs btn-link" data-toggle="collapse" data-target="#jamia2016">Bibtex</a>]</span>
								<div id="jamia2016" class="collapse">
									@article{zhao2016new,<br>
									  title={A new visual navigation system for exploring biomedical Open Educational Resource (OER) videos},<br>
									  author={Zhao, Baoquan and Xu, Songhua and Lin, Shujin and Luo, Xiaonan and Duan, Lian},<br>
									  journal={Journal of the American Medical Informatics Association},<br>
									  volume={23},<br>
									  number={e1},<br>
									  pages={e34--e41},<br>
									  year={2016},<br>
									  publisher={Oxford University Press}<br>
									}
								</div>
								</p> 
							</div>
						</div>








						<p class="sub_title">Other Topics</p>
						<div class="row pub_div_blk">
    					<div class="col-md-3 img_div">
								<img alt="" src="img/cmpb2021.jpg" class="div_img">
							</div>
							<div class="col-md-9">
								<p class="paper_info">F. Wang, S. Xu, D. Jiang, <span class="author">B. Zhao</span>, X. Dai, T. Zhou, and X. Luo, <span class="paper_title"> Particle Hydrodynamic Simulation of Thrombus Formation Using Velocity Decay Factor</span>, <span class="journal">Computer Methods and Programs in Biomedicine</span>,  2021 (Accepted)</p>
								<p class="paper_abs">The proposed method for thrombus formation simulation mainly consists of three steps. First, we formulate the formation of thrombus as a particle-based model and obtain the fibrin concentration of the particles with a discretized form of the convection-diffusion-reaction equation; then, we calculate the velocity decay factor using the obtained fibrin concentration. Finally, the formation of thrombus can be simulated by applying the velocity decay factor on particles.</p>
								
									<span class="bib">[<a href="#" target="_blank"  class="btn-xs btn-link" data-toggle="collapse" data-target="#cmpb2021">Bibtex</a>]</span>
								<div id="cmpb2021" class="collapse">
									@article{wang2021particle,<br>
										  title={Particle hydrodynamic simulation of thrombus formation using velocity decay factor},<br>
										  author={Wang, Fei and Xu, Songhua and Jiang, Dazhi and Zhao, Baoquan and Dong, Xiaoqiang and Zhou, Teng and Luo, Xiaonan},<br>
										  journal={Computer Methods and Programs in Biomedicine},<br>
										  volume={207},<br>
										  pages={106173},<br>
										  year={2021},<br>
										  publisher={Elsevier}<br>
										}
								</div>
								</p> 
							</div>
						</div>


						<div class="row pub_div_blk">
    					<div class="col-md-3 img_div">
								<img alt="" src="img/icip2020.jpg" class="div_img">
							</div>
							<div class="col-md-9">
								<p class="paper_info">J. Hou, W. Lin, and <span class="author">B. Zhao</span>, <span class="paper_title">Content-Dependency Reduction with Multi-Task Learning in Blind Stitched Panoramic Image Quality Assessment</span>, <span class="journal">IEEE International Conference on Image Processing (ICIP)</span>,  pp. 3463-3467, 2020</p>
								<p class="paper_abs">We propose a multi-task learning strategy which encourages learned representation to be less dependent on image content. A siamese network with two weight-shared CNN branches is trained to simultaneously compare the quality of two images of the same scene and predict the quality score of each image.</p>
								<p>
									<span class="bib">[<a href="#" target="_blank"  class="btn-xs btn-link" data-toggle="collapse" data-target="#icip2020">Bibtex</a>]</span>
								<div id="icip2020" class="collapse">
									@inproceedings{hou2020content,<br>
										  title={Content-dependency reduction with multi-task learning in blind stitched panoramic image quality assessment},<br>
										  author={Hou, Jingwen and Lin, Weisi and Zhao, Baoquan},<br>
										  booktitle={2020 IEEE International Conference on Image Processing (ICIP)},<br>
										  pages={3463--3467},<br>
										  year={2020},<br>
										  organization={IEEE}<br>
										}
								</div>
								</p> 
							</div>
						</div>


						<div class="row pub_div_blk">
    					<div class="col-md-3 img_div">
								<img alt="" src="img/sg2018.gif" class="div_img">
							</div>
							<div class="col-md-9">
								<p class="paper_info">F. Wang, S. Lin, R. Wang, Y. Li, <span class="author">B. Zhao</span>, and X. Luo, <span class="paper_title">Improving Incompressible SPH Simulation Efficiency by Integrating Density-Invariant and Divergence-Free Conditions</span>, <span class="journal">ACM SIGGRAPH (Posters)</span>, pp. 1-2, 2018</p>
								<p class="paper_abs">Our method shortens the time of fluid simulation by coupling the two conditions of density-invariant and divergence-free, and achieves the same simulation effect compared with other methods. Further, we regard the displacement of particles as the only basic variable of the continuity equation, which improves the stability of the fluid to a certain extent.</p>
								<p>
									<span class="demo">[<a href="img/sg2018.mp4" download>Demo (MP4, ~70MB)</a>]</span> 
									<span class="bib">[<a href="#" target="_blank"  class="btn-xs btn-link" data-toggle="collapse" data-target="#sg2018">Bibtex</a>]</span>
								<div id="sg2018" class="collapse">
										@incollection{wang2018improving,<br>
										  title={Improving incompressible SPH simulation efficiency by integrating density-invariant and divergence-free conditions},<br>
										  author={Wang, Fei and Lin, Shujin and Wang, Ruomei and Li, Yi and Zhao, Baoquan and Luo, Xiaonan},<br>
										  booktitle={ACM SIGGRAPH 2018 Posters},<br>
										  pages={1--2},<br>
										  year={2018}<br>
										}
								</div>
								</p> 
							</div>
						</div>





							
							
						
    			<p class="sub_title">Patent</p>
    				<ul>
    					<li><span class="author">B. Zhao</span>, and W. Lin, <span class="paper_title">Image-Based Point Cloud Attribute Compression Using Two-Stage Dimensionality Transformation</span>, Singapore Provisional Patent Application No. 10202008512Q, 2020, PCT application (Filed)</li>
    					<li>X. Qi, S. Lin, and <span class="author">B. Zhao</span>, <span class="paper_title">Content-based Movie Video Processing and Visualization</span>, China Patent, CN106649713B, May, 12, 2020 (Awarded)</li>
    			</ul>


				</div>
    	</div>
    </div>



		<div class="container" id="ser_div">
			<div class="row">
    		<div class="blk">
    			<h2>Academic Services</h2>
    			<div class="row">
						<div class="col-md-6">
							<p class="sub_title">Journal Reviewer</p>
							<ul>
								<li>IEEE Transactions on Image Processing</li>
								 <li>IEEE Transactions on  Multimedia</li>
								 <li>Neurocomputing</li>
								 <li>Pattern Recognition</li>
								 <li>Wireless Communications and Mobile Computing</li>
								 <li>IEEE/CAA Journal of Automatica Sinica</li>
								 <li>Signal Processing</li>
								 <li>Frontiers of Computer Science</li>
								 <li>Information Science</li>
							</ul>
						</div>
						<div class="col-md-6">
								<p class="sub_title">Technical Program Committee Member</p>
								<ul>
									<li>IEEE International Conference on Acoustics, Speech and Signal Processing (2021, 2022)</li>
									<li>IEEE International Conference on Multimedia and Expo (2019-2022)<br>
										<span class="highlight"> ICME 2020 Outstanding Reviewer Award</span></li>
									<li>IEEE International Conference on Image Processing (2020-2022)</li>
									<li>American Medical Informatics Association Annual Symposium (2017-2021)</li>
								</ul>
						</div>
					</div>
    		</div>
    	</div>
		</div>


<!-- 		<div class="container" id="res_div">
			<div class="row">
    		<div class="blk">

    			
    			
				</div>
    	</div>
		</div> -->

			<div class="container" id="footer">
				<div class="row">
						<div class="col-md-3">
							<script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=XMw0bkn0aEsI9ambBaXXpMqbU6Z-UjP11v8TJsO3Abc"></script>
						</div>
						<div class="col-md-9">
						</div>
				</div>
				
				<p>Launched in Jun. 2022, last updated in Jun. 2022</p>
			</div>
		<!-- </div> -->

		<a href="#" id="toTopBtn" class="cd-top text-replace js-cd-top cd-top--is-visible cd-top--fade-out" data-abc="true"></a>


    <script src="js/jquery.min.js"></script>
    <script src="js/bootstrap.min.js"></script>
    <script src="js/scripts.js"></script>
    <script type="text/javascript">
    	$('ul.nav').find('a').click(function(){
			    var href = $(this).attr('href');
			    var anchor = $(href).offset();
			    console.log(href);
			     console.log(anchor.top);

			    $('ul.nav').find('a').attr('class', "nav-link");
			    $(this).attr('class', "nav-link active");
			    

			    $("html, body").animate({ scrollTop: anchor.top-80 }, 600);
			    return false;
			});


			$(document).ready(function() {
				$(window).scroll(function() {

				 

				if ($(this).scrollTop() > 20) {
				$('#toTopBtn').fadeIn();
				} else {
				$('#toTopBtn').fadeOut();
				}
				});

				$('#toTopBtn').click(function() {

					$('ul.nav').find('a').attr('class', "nav-link");
			   	$('#home_a').attr('class', "nav-link active");

				$("html, body").animate({
				scrollTop: 0
				}, 1000);
				return false;
				});
				});
    </script>
  </body>
</html>